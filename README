# Confluent
---------



```
  942  cd software/confluent-community-7.3.1/confluent-7.3.1/
  943  code .
  944  cd bin
  945  nohup ./kafka-server-start ../etc/kafka/server.properties &
  946  jps
  947  ./kafka-console-consumer --bootstrap-server 172.20.231.228:9092 --from-beginning --topic connect-testjps
  948  ./kafka-console-consumer --bootstrap-server 172.29.207.104:9092 --from-beginning --topic connect-test
  949  ./kafka-console-consumer --bootstrap-server 172.29.207.42:9092 --from-beginning --topic connect-test
  950  clear
  951  nohup ./kafka-server-start ../etc/kafka/server.properties &
  952  jps
  953  nohup ./kafka-server-start ../etc/kafka/server.properties &
  954  jps
  955  clear
  956  ./kafka-console-consumer --bootstrap-server 172.29.207.42:9092 --from-beginning --topic connect-test
  957  ./kafka-topics --bootstrap-server 172.20.231.228:9092 --delete --topic connect-test
  958  ip a | grep eth0
  959  ./kafka-topics --bootstrap-server 172.20.231.228:9092 --delete --topic connect-test
  960  ./kafka-topics --bootstrap-server 172.20.226.44:9092 --list
  961  ./kafka-topics --bootstrap-server 172.29.207.42:9092 --delete --topic __consumer_offsets
  962  ./kafka-topics --bootstrap-server 172.29.207.42:9092 --delete --topic __schemas
  963  ./kafka-topics --bootstrap-server 172.29.207.42:9092 --delete --topic _schemas
  964  ./kafka-topics --bootstrap-server 172.20.231.228:9092 --create --topic connect-test --config cleanup.policy=compact
./connect-standalone ../etc/kafka/connect-standalone.properties ../etc/kafka/connect-file-source.properties ../etc/kafka/connect-file-sink.properties 
```
Confluent offers a real-time data platform built around Apache Kafka.

Apache Kafka, an open source technology created by the founders of Confluent,
acts as a real-time, fault tolerant, highly scalable messaging system. It is
widely adopted for use cases ranging from collecting user activity data, logs,
application metrics, stock ticker data, and device instrumentation. Its key
strength is its ability to make high volume data available as a real-time stream
for consumption in systems with very different requirementsâ€”from batch systems
like Hadoop, to realtime systems that require low-latency access, to stream
processing engines that transform the data streams as they arrive.

This infrastructure lets you build around a single central nervous system
transmitting messages to all the different systems and applications within your
company.
